{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "L13/8 DenseNet",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s0DimgqtFlj"
      },
      "source": [
        "### Densely Connected Networks (DenseNet)\n",
        "\n",
        "![The main difference between ResNet (left) and DenseNet (right) in cross-layer connections: use of addition and use of concatenation. ](http://www.d2l.ai/_images/densenet.svg)\n",
        "\n",
        "$$\\mathbf{x} \\to \\left[\\mathbf{x}, f_1(\\mathbf{x}), f_2(\\mathbf{x}, f_1(\\mathbf{x})), f_3(\\mathbf{x}, f_1(\\mathbf{x}), f_2(\\mathbf{x}, f_1(\\mathbf{x})), \\ldots\\right]$$\n",
        "\n",
        "![Dense connections in DenseNet](http://www.d2l.ai/_images/DenseNetDense.svg)\n",
        "\n",
        "### Dense Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "UfhAcD3itFll"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T4QklBytFlo"
      },
      "source": [
        "A dense block consists of multiple `conv_block` units, each using the same number of output channels. In the forward computation, however, we concatenate the input and output of each block on the channel dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "2"
        },
        "id": "11jd_QvatFlo"
      },
      "source": [
        "def conv_block(input_channels, num_channels):\n",
        "    blk = nn.Sequential(nn.BatchNorm2d(input_channels), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))\n",
        "    return blk\n",
        "    \n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_convs, input_channels, num_channels):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layer = []\n",
        "        for i in range(num_convs):\n",
        "            layer.append(conv_block((num_channels * i + input_channels), num_channels))\n",
        "        self.net = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        for blk in self.net:\n",
        "            Y = blk(X)\n",
        "            # Concatenate the input and output of each block on the channel dimension.\n",
        "            X = torch.cat((X, Y), dim=1)  \n",
        "        return X"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCtJzr02tFlq"
      },
      "source": [
        "Testing it with data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "id": "jT_s3e93tFlr",
        "outputId": "7326d02a-6862-4447-a623-a5723a3ef6c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "blk = DenseBlock(2, 3, 10)\n",
        "X = torch.randn(4, 3, 8, 8)\n",
        "Y = blk(X)\n",
        "Y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 23, 8, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDa30D00tFlu"
      },
      "source": [
        "### Transition Layers to reduce dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "3"
        },
        "id": "Ak0AETuTtFlu"
      },
      "source": [
        "def transition_block(input_channels, num_channels):\n",
        "    blk = nn.Sequential(\n",
        "            nn.BatchNorm2d(input_channels), \n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "    return blk"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcTjq7kHtFlx",
        "outputId": "24c47b9a-6fb9-4ecf-f9ff-4a7477c93d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "blk = transition_block(23, 10)\n",
        "print(Y.shape)\n",
        "print(blk(Y).shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 23, 8, 8])\n",
            "torch.Size([4, 10, 4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaLEVPNvtFlz"
      },
      "source": [
        "### DenseNet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25CKfMXatFl0"
      },
      "source": [
        "class flatten(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "net_1 = nn.Sequential(\n",
        "        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxt7XDNotFl3"
      },
      "source": [
        "4 dense blocks with a transition layer in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "alxWafgBtFl3"
      },
      "source": [
        "num_channels, growth_rate = 64, 32  # Num_channels: the current number of channels.\n",
        "num_convs_in_dense_blocks = [4, 4, 4, 4]\n",
        "\n",
        "net_2 = []\n",
        "for i, num_convs in enumerate(num_convs_in_dense_blocks):\n",
        "    net_2.append(DenseBlock(num_convs, num_channels, growth_rate))\n",
        "    # This is the number of output channels in the previous dense block.\n",
        "    num_channels += num_convs * growth_rate\n",
        "    # A transition layer that haves the number of channels is added between the dense blocks.\n",
        "    if i != len(num_convs_in_dense_blocks) - 1:\n",
        "        net_2.append(transition_block(num_channels, num_channels // 2))\n",
        "        num_channels = num_channels // 2\n",
        "net_2 = nn.Sequential(*net_2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AfVUZIXtFl5"
      },
      "source": [
        "### Last stage\n",
        "\n",
        "Similar to ResNet, a global pooling layer and fully connected layer are connected at the end to produce the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAeXjAqxtFl6"
      },
      "source": [
        "net = nn.Sequential(\n",
        "        net_1,\n",
        "        net_2,\n",
        "        nn.BatchNorm2d(num_channels), \n",
        "        nn.ReLU(), \n",
        "        nn.AdaptiveMaxPool2d((1,1)),\n",
        "        flatten(),\n",
        "        nn.Linear(num_channels, 10)\n",
        "        )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQXMsV-ItFl8"
      },
      "source": [
        "### Data Acquisition and Training\n",
        "\n",
        "Since we are using a deeper network here we only use 96x96 images for speed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50lAKKkotFl8",
        "outputId": "9f84f9a5-d13c-48ab-e9e0-00963162078b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "    acc_sum,n = 0,0\n",
        "    for (imgs, labels) in data_iter:\n",
        "        # send data to the GPU if cuda is availabel\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            labels = labels.long()\n",
        "            acc_sum += torch.sum((torch.argmax(net(imgs), dim=1) == labels)).float()\n",
        "            n += labels.shape[0]\n",
        "    return acc_sum.item()/n\n",
        "\n",
        "def weights_init(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Training using GPU.')\n",
        "    net.cuda()\n",
        "else:\n",
        "    print('Training using CPU.')\n",
        "\n",
        "#Initialize network parameters.\n",
        "net.apply(weights_init)\n",
        "\n",
        "lr, num_epochs, batch_size = 0.1, 5, 128\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# Apply resize to 96*96 at trasfrom\n",
        "transform = transforms.Compose([transforms.Resize(96),\n",
        "                                transforms.ToTensor()\n",
        "                                ]) \n",
        "mnist_trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "# Loading training set and test set using DataLoader.\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "from tqdm import tqdm\n",
        "for epoch in range(num_epochs):\n",
        "    net.train() # Switch to training mode\n",
        "    n, start = 0, time.time()\n",
        "    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_iter = iter(train_loader)\n",
        "    # for _, (X, y) in tqdm(enumerate(train_iter)):\n",
        "    for X, y in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "            train_l_sum = train_l_sum.cuda()\n",
        "            train_acc_sum = train_acc_sum.cuda()\n",
        "        y_hat = net(X)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y = y.long()\n",
        "            train_l_sum += loss.float()\n",
        "            train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
        "            n += y.shape[0]\n",
        "\n",
        "    test_acc = evaluate_accuracy(iter(test_loader), net) \n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
        "        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training using GPU.\n",
            "epoch 1, loss 0.0047, train acc 0.801, test acc 0.877, time 33.0 sec\n",
            "epoch 2, loss 0.0025, train acc 0.882, test acc 0.883, time 33.6 sec\n",
            "epoch 3, loss 0.0021, train acc 0.902, test acc 0.832, time 33.9 sec\n",
            "epoch 4, loss 0.0018, train acc 0.913, test acc 0.892, time 33.7 sec\n",
            "epoch 5, loss 0.0016, train acc 0.922, test acc 0.912, time 33.8 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}