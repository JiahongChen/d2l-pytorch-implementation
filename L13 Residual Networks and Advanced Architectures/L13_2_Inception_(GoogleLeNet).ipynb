{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "L13/2 Inception (GoogleLeNet)",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvJeZyqj3Exj"
      },
      "source": [
        "### Inception\n",
        "\n",
        "![Structure of the Inception block. ](http://www.d2l.ai/_images/inception.svg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmLASfe43Exk"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "iRBhwkOg3Exn"
      },
      "source": [
        "class Inception(nn.Module):\n",
        "    # c1 - c4 are the number of output channels for each layer in the path.\n",
        "    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):\n",
        "        super(Inception, self).__init__(**kwargs)\n",
        "        # Path 1 is a single 1 x 1 convolutional layer.\n",
        "        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n",
        "        # Path 2 is a 1 x 1 convolutional layer followed by a 3 x 3 convolutional layer.\n",
        "        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n",
        "        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n",
        "        # Path 3 is a 1 x 1 convolutional layer followed by a 5 x 5 convolutional layer.\n",
        "        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n",
        "        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n",
        "        # Path 4 is a 3 x 3 maximum pooling layer followed by a 1 x 1 convolutional layer.\n",
        "        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n",
        "        # Activation function\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        p1 = self.relu(self.p1_1(x))\n",
        "        p2 = self.relu(self.p2_2(self.relu(self.p2_1(x))))\n",
        "        p3 = self.relu(self.p3_2(self.relu(self.p3_1(x))))\n",
        "        p4 = self.relu(self.p4_2(self.p4_1(x)))\n",
        "        # Concatenate the outputs on the channel dimension\n",
        "        return torch.cat((p1, p2, p3, p4), dim=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIR7DNoj3Exq"
      },
      "source": [
        "### Inception Model - Stage 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "2"
        },
        "id": "RoLEC3TM3Exq"
      },
      "source": [
        "b1 = nn.Sequential(\n",
        "       nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n",
        "       nn.ReLU(),\n",
        "       nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "       )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbZg3op23Ext"
      },
      "source": [
        "### Inception Model - Stage 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "3"
        },
        "id": "gHvqM4BO3Ext"
      },
      "source": [
        "b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n",
        "       nn.ReLU(),\n",
        "       nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "       nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "       )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr0z5MHW3Exx"
      },
      "source": [
        "### Inception Model - Stage 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "4"
        },
        "id": "C5KCL8zr3Exy"
      },
      "source": [
        "b3 = nn.Sequential(\n",
        "       Inception(192, 64, (96, 128), (16, 32), 32),\n",
        "       Inception(256, 128, (128, 192), (32, 96), 64),\n",
        "       nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "       )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th_cRhpN3Ex0"
      },
      "source": [
        "### Inception Model - Stage 4\n",
        "\n",
        "We use a total of 512 channels (128 + 256 + 64 + 64) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "od5w_Fz73Ex0"
      },
      "source": [
        "b4 = nn.Sequential(\n",
        "       Inception(480, 192, (96, 208), (16, 48), 64),\n",
        "       Inception(512, 160, (112, 224), (24, 64), 64),\n",
        "       Inception(512, 128, (128, 256), (24, 64), 64),\n",
        "       Inception(512, 112, (144, 288), (32, 64), 64),\n",
        "       Inception(528, 256, (160, 320), (32, 128), 128),\n",
        "       nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "       )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFQx9eTi3Ex3"
      },
      "source": [
        "### Inception Model - Stage 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "id": "7ZpwcS6w3Ex3"
      },
      "source": [
        "b5 = nn.Sequential(\n",
        "       Inception(832, 256, (160, 320), (32, 128), 128),\n",
        "       Inception(832, 384, (192, 384), (48, 128), 128),\n",
        "       nn.AdaptiveMaxPool2d((1,1))\n",
        "       )\n",
        "\n",
        "class flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "def weights_init(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "net = nn.Sequential(\n",
        "        *b1, \n",
        "        *b2, \n",
        "        *b3, \n",
        "        *b4, \n",
        "        *b5, \n",
        "        flatten(),\n",
        "        nn.Linear(1024, 10)\n",
        "        )\n",
        "\n",
        "net = net.apply(weights_init)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ag66Uue3Ex5"
      },
      "source": [
        "Priming the network (at full size)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "7"
        },
        "id": "jkqeeDsz3Ex6",
        "outputId": "2d34ee35-2c8d-4e5b-ebb7-90495c8acd30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "X = torch.randn(size=(1, 1, 96, 96))\n",
        "for layer in net:\n",
        "    X = layer(X)\n",
        "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv2d output shape:\t torch.Size([1, 64, 48, 48])\n",
            "ReLU output shape:\t torch.Size([1, 64, 48, 48])\n",
            "MaxPool2d output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Conv2d output shape:\t torch.Size([1, 64, 24, 24])\n",
            "ReLU output shape:\t torch.Size([1, 64, 24, 24])\n",
            "Conv2d output shape:\t torch.Size([1, 192, 24, 24])\n",
            "MaxPool2d output shape:\t torch.Size([1, 192, 12, 12])\n",
            "Inception output shape:\t torch.Size([1, 256, 12, 12])\n",
            "Inception output shape:\t torch.Size([1, 480, 12, 12])\n",
            "MaxPool2d output shape:\t torch.Size([1, 480, 6, 6])\n",
            "Inception output shape:\t torch.Size([1, 512, 6, 6])\n",
            "Inception output shape:\t torch.Size([1, 512, 6, 6])\n",
            "Inception output shape:\t torch.Size([1, 512, 6, 6])\n",
            "Inception output shape:\t torch.Size([1, 528, 6, 6])\n",
            "Inception output shape:\t torch.Size([1, 832, 6, 6])\n",
            "MaxPool2d output shape:\t torch.Size([1, 832, 3, 3])\n",
            "Inception output shape:\t torch.Size([1, 832, 3, 3])\n",
            "Inception output shape:\t torch.Size([1, 1024, 3, 3])\n",
            "AdaptiveMaxPool2d output shape:\t torch.Size([1, 1024, 1, 1])\n",
            "flatten output shape:\t torch.Size([1, 1024])\n",
            "Linear output shape:\t torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOZ0BQmC3Ex8"
      },
      "source": [
        "## Data Acquisition and Training\n",
        "\n",
        "As before, we train our model using the Fashion-MNIST dataset. We transform it to $96 \\times 96$ pixel resolution before invoking the training procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "8"
        },
        "id": "t7c0hJ-C3Ex9",
        "outputId": "35c98a44-fffe-44fd-935c-e5e3094cfec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "    acc_sum,n = 0,0\n",
        "    for (imgs, labels) in data_iter:\n",
        "        # send data to the GPU if cuda is availabel\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            labels = labels.long()\n",
        "            acc_sum += torch.sum((torch.argmax(net(imgs), dim=1) == labels)).float()\n",
        "            n += labels.shape[0]\n",
        "    return acc_sum.item()/n\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Training using GPU.')\n",
        "    net.cuda()\n",
        "else:\n",
        "    print('Training using CPU.')\n",
        "\n",
        "#Initialize network parameters.\n",
        "net.apply(weights_init)\n",
        "\n",
        "lr, num_epochs, batch_size = 0.1, 5, 128\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "# Apply resize to 96*96 at trasfrom\n",
        "transform = transforms.Compose([transforms.Resize(96),\n",
        "                                transforms.ToTensor()\n",
        "                                ]) \n",
        "mnist_trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "# Loading training set and test set using DataLoader.\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=batch_size,\n",
        "    shuffle=True, num_workers=0)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "from tqdm import tqdm\n",
        "for epoch in range(num_epochs):\n",
        "    net.train() # Switch to training mode\n",
        "    n, start = 0, time.time()\n",
        "    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_iter = iter(train_loader)\n",
        "    # for _, (X, y) in tqdm(enumerate(train_iter)):\n",
        "    for X, y in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "            train_l_sum = train_l_sum.cuda()\n",
        "            train_acc_sum = train_acc_sum.cuda()\n",
        "        y_hat = net(X)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y = y.long()\n",
        "            train_l_sum += loss.float()\n",
        "            train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
        "            n += y.shape[0]\n",
        "\n",
        "    test_acc = evaluate_accuracy(iter(test_loader), net) \n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
        "        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training using GPU.\n",
            "epoch 1, loss 0.0150, train acc 0.287, test acc 0.549, time 47.0 sec\n",
            "epoch 2, loss 0.0053, train acc 0.737, test acc 0.776, time 47.1 sec\n",
            "epoch 3, loss 0.0036, train acc 0.827, test acc 0.817, time 47.4 sec\n",
            "epoch 4, loss 0.0030, train acc 0.856, test acc 0.844, time 47.3 sec\n",
            "epoch 5, loss 0.0027, train acc 0.870, test acc 0.871, time 47.3 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}