{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "L15/3 Fine Tuning",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hS_mvkCmE7N"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "NNMIH1RWmE7O"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SV9B7J1mE7R"
      },
      "source": [
        "## Hot Dog Recognition Dataset\n",
        "\n",
        "\n",
        "### Download the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye-bodVBnEon",
        "outputId": "dc55bdbf-f1aa-4348-bd19-9a6ff26a6d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import requests, zipfile, io\n",
        "r = requests.get('https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.zip')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall(\"./data\")\n",
        "# list dataset folder as a tree\n",
        "# source: https://stackoverflow.com/questions/3455625/linux-command-to-print-directory-structure-in-the-form-of-a-tree\n",
        "! ls -R ./data/hotdog/ | grep \":$\" | sed -e 's/:$//' -e 's/[^-][^\\/]*\\//--/g' -e 's/^/   /' -e 's/-/|/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   |-----\n",
            "   |-----test\n",
            "   |-------hotdog\n",
            "   |-------not-hotdog\n",
            "   |-----train\n",
            "   |-------hotdog\n",
            "   |-------not-hotdog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bepCrKOcmE7W"
      },
      "source": [
        "### Read the Dataset and Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKD7lbRupfZq"
      },
      "source": [
        "def load_dataset(type = 'train'):\n",
        "    normalize = transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    if type == 'train':\n",
        "        data_path = './data/hotdog/train/'\n",
        "        # We specify the mean and variance of the three RGB channels to normalize the image channel.\n",
        "        transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize])\n",
        "    elif type == 'test':\n",
        "        data_path = './data/hotdog/test/'\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            normalize])\n",
        "    else:\n",
        "        raise Exception('Undefined data type')\n",
        "\n",
        "    train_dataset = torchvision.datasets.ImageFolder(\n",
        "        root=data_path,\n",
        "        transform=transform\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=64,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader\n",
        "\n",
        "train_loader = load_dataset('train')\n",
        "test_loader = load_dataset('test')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYppgE8-mE7d"
      },
      "source": [
        "## Model \n",
        "\n",
        "### Train with pre-trained Models\n",
        "\n",
        "*Note that in PyTorch model resnet18, we cannot modify the number of output classes directly, since it will fail to load the fc layer weights and bias from the checkpoint.*\n",
        "\n",
        "Nevertheless, we can remove the last layer (the incorrect fc layer) of the pretrained model and then add a suitable fc layer and initialize it.\n",
        "\n",
        "ref: [toch forum](https://discuss.pytorch.org/t/how-to-replace-last-layer-in-sequential/14422)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "id": "E8tIw9phmE7d"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "def fc_weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        # m.bias.data.normal_(0.0, 0.01)\n",
        "\n",
        "class flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "# pre-trained net with unwanted layer structures.\n",
        "pretrained_net = models.resnet18(pretrained=True)\n",
        "\n",
        "# remove last layer (fc layer) from new_net\n",
        "removed = list(pretrained_net.children())[:-1]\n",
        "# Now new_new come with desired fc layer but still does not come with \n",
        "# pre-trained weights and bias\n",
        "pretrained_net= torch.nn.Sequential(*removed)\n",
        "\n",
        "pretrained_net = torch.nn.Sequential(pretrained_net, \n",
        "                                     flatten(),\n",
        "                                     torch.nn.Linear(512,2))\n",
        "\n",
        "# here we only init the last fc layer\n",
        "pretrained_net = pretrained_net.apply(fc_weights_init)\n",
        "# print(pretrained_net)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRkZAgcyuWDt",
        "outputId": "2373e6b0-c162-403b-9bef-0879227c195e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def evaluate_accuracy(data_iter, net):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "    acc_sum,n = 0,0\n",
        "    for (imgs, labels) in data_iter:\n",
        "        # send data to the GPU if cuda is availabel\n",
        "        if torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            labels = labels.long()\n",
        "            acc_sum += torch.sum((torch.argmax(net(imgs), dim=1) == labels)).float()\n",
        "            n += labels.shape[0]\n",
        "    return acc_sum.item()/n\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Training using GPU.')\n",
        "    pretrained_net.cuda()\n",
        "else:\n",
        "    print('Training using CPU.')\n",
        "\n",
        "lr, num_epochs, batch_size, weight_decay = 0.01, 5, 128, 0.001\n",
        "optimizer = torch.optim.SGD(pretrained_net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    pretrained_net.train() # Switch to training mode\n",
        "    n, start = 0, time.time()\n",
        "    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_iter = iter(train_loader)\n",
        "    # for _, (X, y) in tqdm(enumerate(train_iter)):\n",
        "    for X, y in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "            train_l_sum = train_l_sum.cuda()\n",
        "            train_acc_sum = train_acc_sum.cuda()\n",
        "        y_hat = pretrained_net(X)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y = y.long()\n",
        "            train_l_sum += loss.float()\n",
        "            train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
        "            n += y.shape[0]\n",
        "\n",
        "    test_acc = evaluate_accuracy(iter(test_loader), pretrained_net) \n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
        "        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training using GPU.\n",
            "epoch 1, loss 0.0066, train acc 0.821, test acc 0.886, time 13.3 sec\n",
            "epoch 2, loss 0.0039, train acc 0.905, test acc 0.904, time 13.1 sec\n",
            "epoch 3, loss 0.0031, train acc 0.924, test acc 0.927, time 13.3 sec\n",
            "epoch 4, loss 0.0025, train acc 0.939, test acc 0.936, time 13.2 sec\n",
            "epoch 5, loss 0.0024, train acc 0.945, test acc 0.944, time 13.2 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4VrcTOH9wU3"
      },
      "source": [
        "### Train with Non-trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kZV_Rx4v-rr",
        "outputId": "88aaa84f-c3eb-4e2c-c78d-c3a4c68627e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.01)\n",
        "\n",
        "pretrained_net = models.resnet18(num_classes=2, pretrained=False)\n",
        "pretrained_net = pretrained_net.apply(weights_init)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('Training using GPU.')\n",
        "    pretrained_net.cuda()\n",
        "else:\n",
        "    print('Training using CPU.')\n",
        "\n",
        "lr, num_epochs, batch_size, weight_decay = 0.01, 5, 128, 0.001\n",
        "optimizer = torch.optim.SGD(pretrained_net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    pretrained_net.train() # Switch to training mode\n",
        "    n, start = 0, time.time()\n",
        "    train_l_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_acc_sum = torch.tensor([0.0], dtype=torch.float32)\n",
        "    train_iter = iter(train_loader)\n",
        "    # for _, (X, y) in tqdm(enumerate(train_iter)):\n",
        "    for X, y in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "            train_l_sum = train_l_sum.cuda()\n",
        "            train_acc_sum = train_acc_sum.cuda()\n",
        "        y_hat = pretrained_net(X)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            y = y.long()\n",
        "            train_l_sum += loss.float()\n",
        "            train_acc_sum += (torch.sum((torch.argmax(y_hat, dim=1) == y))).float()\n",
        "            n += y.shape[0]\n",
        "\n",
        "    test_acc = evaluate_accuracy(iter(test_loader), pretrained_net) \n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\\\n",
        "        % (epoch + 1, train_l_sum/n, train_acc_sum/n, test_acc, time.time() - start))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training using GPU.\n",
            "epoch 1, loss 0.0076, train acc 0.778, test acc 0.560, time 13.2 sec\n",
            "epoch 2, loss 0.0066, train acc 0.812, test acc 0.789, time 13.2 sec\n",
            "epoch 3, loss 0.0062, train acc 0.829, test acc 0.735, time 13.2 sec\n",
            "epoch 4, loss 0.0058, train acc 0.845, test acc 0.845, time 13.2 sec\n",
            "epoch 5, loss 0.0058, train acc 0.839, test acc 0.764, time 13.2 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
