{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "L10/2 Blocks and Layers",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCunpkHJVliv"
      },
      "source": [
        "# Layers and Blocks\n",
        "\n",
        "## Construct a MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:11.838843Z",
          "start_time": "2019-02-08T00:46:56.524987Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "kY3e65dfVliw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "net = nn.Sequential(nn.Linear(20, 256),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(256,10)\n",
        "                    )"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWjfJwnNVliz"
      },
      "source": [
        "### Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:12.061751Z",
          "start_time": "2019-02-08T00:47:11.851762Z"
        },
        "id": "ObD0glGNVli0",
        "outputId": "4ded6100-82d8-4de2-c582-038efae7b475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(size=(2, 20))\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        # Initialize weight parameter by a normal distribition \n",
        "        # with a mean of 0 and standard deviation of 0.01.\n",
        "        nn.init.normal_(m.weight.data, std=0.01)\n",
        "        # The bias parameter is initialized to zero by default.\n",
        "        m.bias.data.fill_(0.0)\n",
        "\n",
        "net.apply(init_weights)\n",
        "net(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6703e-04, -1.1188e-03, -1.5502e-03, -3.7548e-03, -1.3014e-04,\n",
              "          4.5263e-03,  1.2260e-03, -1.9469e-03, -1.0568e-03,  8.9062e-04],\n",
              "        [ 2.9756e-05,  1.4792e-04, -4.5574e-04, -6.7872e-04,  5.3927e-04,\n",
              "          4.6126e-03,  5.9986e-04,  1.3424e-03, -2.8244e-03,  2.9399e-03]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh2zrQYDVli4"
      },
      "source": [
        "## Implement the Same MLP with A Custom Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:12.133035Z",
          "start_time": "2019-02-08T00:47:12.066183Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "1"
        },
        "id": "VsrAG-zSVli4"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.hidden = nn.Linear(20, 256)  \n",
        "        self.relu = nn.ReLU()\n",
        "        self.output = nn.Linear(256, 10) \n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(self.relu(self.hidden(x)))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_hixkLGVli7"
      },
      "source": [
        "### Forward "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:12.167779Z",
          "start_time": "2019-02-08T00:47:12.140618Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "2"
        },
        "id": "UQh3i0QSVli7",
        "outputId": "b4ec3374-b9ac-48d7-d7a5-ae7d6f162d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "net = MLP()\n",
        "net.apply(init_weights)\n",
        "net(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0001,  0.0007, -0.0021,  0.0013,  0.0041, -0.0046,  0.0039,  0.0027,\n",
              "         -0.0002, -0.0017],\n",
              "        [ 0.0035,  0.0029, -0.0016,  0.0032,  0.0027, -0.0026,  0.0025,  0.0016,\n",
              "         -0.0010, -0.0016]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0YBgsyVljE"
      },
      "source": [
        "## Blocks with Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:12.246541Z",
          "start_time": "2019-02-08T00:47:12.223758Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "5"
        },
        "id": "cq3aMvDAVljE"
      },
      "source": [
        "class FancyMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FancyMLP, self).__init__()\n",
        "        # Random weight parameters are not iterated during training\n",
        "        self.rand_weight = nn.Parameter(torch.empty(20,20).uniform_(0, 1))\n",
        "        self.fc1 = nn.Linear(20, 20)\n",
        "        self.fc2 = nn.Linear(20, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        # This layer will not be updated during training.\n",
        "        x = self.relu(torch.matmul(x, torch.autograd.Variable(self.rand_weight).data) + 1)\n",
        "        # Reuse the fully connected layer. \n",
        "        x = self.fc2(x)\n",
        "        while x.norm().item() > 1:\n",
        "            x /= 2\n",
        "        if x.norm().item() < 0.8:\n",
        "            x *= 10\n",
        "        return x.sum()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM5jh_ijVljH"
      },
      "source": [
        "### Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:12.324575Z",
          "start_time": "2019-02-08T00:47:12.297772Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "6"
        },
        "id": "PCrQadDiVljI",
        "outputId": "0f29300c-0dc8-42ea-91b4-9b5a93400a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net = FancyMLP()\n",
        "net.apply(init_weights)\n",
        "net(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-3.3616, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j1MapC7VljL"
      },
      "source": [
        "## Mix Things Together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-02-08T00:47:12.364915Z",
          "start_time": "2019-02-08T00:47:12.332897Z"
        },
        "attributes": {
          "classes": [],
          "id": "",
          "n": "7"
        },
        "id": "BBpFp0JdVljM",
        "outputId": "a738ee07-e985-4311-c0f6-964389994ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "class NestMLP(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NestMLP, self).__init__(**kwargs)\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(64, 32),\n",
        "                                 nn.ReLU()\n",
        "                                 )\n",
        "        self.fc = nn.Linear(32, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.fc(self.net(x)))\n",
        "    \n",
        "chimera = NestMLP()\n",
        "chimera.apply(init_weights)\n",
        "print(chimera)\n",
        "chimera(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NestMLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (fc): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000e+00, 4.2913e-05, 0.0000e+00, 7.0529e-05, 0.0000e+00, 1.8853e-05,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         7.3905e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 3.8530e-05, 0.0000e+00, 8.4401e-05, 0.0000e+00, 7.9739e-06,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         6.3707e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}
